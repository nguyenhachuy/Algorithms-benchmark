{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from statistics import mean\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADULT_PATH = './adult/adult.pkl'\n",
    "DOTA_PATH = './dota2Dataset/dota2Train.pkl'\n",
    "CONNECT_4_PATH = './connect-4/connect-4.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "(10000, 108) (10000, 115) (10000, 42)\n",
      "[-1  1] [-1  1] [ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "\n",
    "adult = pickle.load(open(ADULT_PATH, 'rb'))\n",
    "dota = pickle.load(open(DOTA_PATH, 'rb'))\n",
    "connect = pickle.load(open(CONNECT_4_PATH, 'rb'))\n",
    "\n",
    "#test\n",
    "adult = adult.iloc[:10000, :]\n",
    "dota = dota.iloc[:10000, :]\n",
    "connect = connect.iloc[:10000, :]\n",
    "\n",
    "adult_label = adult.iloc[:,0]\n",
    "dota_label = dota.iloc[:,0]\n",
    "connect_label = connect.iloc[:,0]\n",
    "\n",
    "adult.drop(columns='label', inplace=True)\n",
    "dota.drop(columns='label', inplace=True)\n",
    "connect.drop(columns='label', inplace=True)\n",
    "\n",
    "adult = pd.get_dummies(adult)\n",
    "dota = pd.get_dummies(dota)\n",
    "connect = pd.get_dummies(connect)\n",
    "\n",
    "print(type(adult), type(dota), type(connect))\n",
    "print(adult.shape, dota.shape, connect.shape)\n",
    "print(adult_label.unique(), dota_label.unique(), connect_label.unique())\n",
    "\n",
    "datasets = [adult.values, dota.values, connect.values]\n",
    "labels = [adult_label.values, dota_label.values, connect_label.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition schemes and classifiers\n",
    "partitions = [0.2, 0.5, 0.8]\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=1024, max_depth=10, random_state=0, n_jobs=-1)\n",
    "max_features = [1,2,4,6,8,12,16,20]\n",
    "parameters_1 = {'clf__max_features': max_features}\n",
    "\n",
    "lgc = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "penalty = ['l1', 'l2']\n",
    "C = [10**x for x in range(-8,5)]\n",
    "parameters_2 = {'clf__penalty': penalty, 'clf__C': C}\n",
    "\n",
    "svc = SVC(gamma='auto')\n",
    "C = [10**x for x in range(-7,3)]\n",
    "kernel = ['linear', 'poly']\n",
    "degree = [2,3]\n",
    "parameters_3 = {'clf__C': C, 'clf__kernel': kernel, 'clf__degree': degree}\n",
    "\n",
    "clfs = [\n",
    "    RandomForestClassifier(n_estimators=1024, max_depth=20, random_state=0, n_jobs=-1), \n",
    "    LogisticRegression(random_state=0, n_jobs=-1),\n",
    "    SVC(gamma='auto')\n",
    "]\n",
    "\n",
    "parameters = [parameters_1, parameters_2, parameters_3]\n",
    "clf_names = ['rf', 'lg', 'svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0, dataset 0, partition 0.2, trial 0\n",
      "Accuracy: 0.865\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Classifier 0, dataset 0, partition 0.2, trial 1\n",
      "Accuracy: 0.8555\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Classifier 0, dataset 0, partition 0.2, trial 2\n",
      "Accuracy: 0.863\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=16, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 16}\n",
      "Average test accuracy for rf, 0, 0.2: 0.8611666666666666\n",
      "Average train accuracy for rf, 0, 0.2: 0.9744167309793953\n",
      "Average val accuracy for rf, 0, 0.2: 0.8558749507466822\n",
      "Classifier 0, dataset 0, partition 0.5, trial 0\n",
      "Accuracy: 0.8596\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Classifier 0, dataset 0, partition 0.5, trial 1\n",
      "Accuracy: 0.8638\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Classifier 0, dataset 0, partition 0.5, trial 2\n",
      "Accuracy: 0.8546\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Average test accuracy for rf, 0, 0.5: 0.8593333333333334\n",
      "Average train accuracy for rf, 0, 0.5: 0.9771664424128931\n",
      "Average val accuracy for rf, 0, 0.5: 0.8541336833167585\n",
      "Classifier 0, dataset 0, partition 0.8, trial 0\n",
      "Accuracy: 0.84825\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Classifier 0, dataset 0, partition 0.8, trial 1\n",
      "Accuracy: 0.850125\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Classifier 0, dataset 0, partition 0.8, trial 2\n",
      "Accuracy: 0.85375\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 8}\n",
      "Average test accuracy for rf, 0, 0.8: 0.8507083333333333\n",
      "Average train accuracy for rf, 0, 0.8: 0.9948337909064973\n",
      "Average val accuracy for rf, 0, 0.8: 0.8466637552094823\n",
      "Classifier 0, dataset 1, partition 0.2, trial 0\n",
      "Accuracy: 0.547\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 4}\n",
      "Classifier 0, dataset 1, partition 0.2, trial 1\n",
      "Accuracy: 0.5585\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 8}\n",
      "Classifier 0, dataset 1, partition 0.2, trial 2\n",
      "Accuracy: 0.5695\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 8}\n",
      "Average test accuracy for rf, 1, 0.2: 0.5583333333333333\n",
      "Average train accuracy for rf, 1, 0.2: 0.9816875775624321\n",
      "Average val accuracy for rf, 1, 0.2: 0.5693750086697087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0, dataset 1, partition 0.5, trial 0\n",
      "Accuracy: 0.5618\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=16, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 16}\n",
      "Classifier 0, dataset 1, partition 0.5, trial 1\n",
      "Accuracy: 0.5608\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=4, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 4}\n",
      "Classifier 0, dataset 1, partition 0.5, trial 2\n",
      "Accuracy: 0.5614\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=6, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 6}\n",
      "Average test accuracy for rf, 1, 0.5: 0.5613333333333334\n",
      "Average train accuracy for rf, 1, 0.5: 0.9932666132040118\n",
      "Average val accuracy for rf, 1, 0.5: 0.5626002450570311\n",
      "Classifier 0, dataset 1, partition 0.8, trial 0\n",
      "Accuracy: 0.555875\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=6, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 6}\n",
      "Classifier 0, dataset 1, partition 0.8, trial 1\n",
      "Accuracy: 0.551\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Classifier 0, dataset 1, partition 0.8, trial 2\n",
      "Accuracy: 0.547375\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 1}\n",
      "Average test accuracy for rf, 1, 0.8: 0.5514166666666667\n",
      "Average train accuracy for rf, 1, 0.8: 0.999666583124854\n",
      "Average val accuracy for rf, 1, 0.8: 0.5494961028893165\n",
      "Classifier 0, dataset 2, partition 0.2, trial 0\n",
      "Accuracy: 0.915\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Classifier 0, dataset 2, partition 0.2, trial 1\n",
      "Accuracy: 0.919\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=16, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 16}\n",
      "Classifier 0, dataset 2, partition 0.2, trial 2\n",
      "Accuracy: 0.9225\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=20, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 20}\n",
      "Average test accuracy for rf, 2, 0.2: 0.9188333333333334\n",
      "Average train accuracy for rf, 2, 0.2: 0.9999583385410157\n",
      "Average val accuracy for rf, 2, 0.2: 0.9112084139020007\n",
      "Classifier 0, dataset 2, partition 0.5, trial 0\n",
      "Accuracy: 0.9192\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Classifier 0, dataset 2, partition 0.5, trial 1\n",
      "Accuracy: 0.9112\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=16, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 16}\n",
      "Classifier 0, dataset 2, partition 0.5, trial 2\n",
      "Accuracy: 0.9058\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Average test accuracy for rf, 2, 0.5: 0.9120666666666667\n",
      "Average train accuracy for rf, 2, 0.5: 1.0\n",
      "Average val accuracy for rf, 2, 0.5: 0.9036660227640216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0, dataset 2, partition 0.8, trial 0\n",
      "Accuracy: 0.90075\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Classifier 0, dataset 2, partition 0.8, trial 1\n",
      "Accuracy: 0.895\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=8, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 8}\n",
      "Classifier 0, dataset 2, partition 0.8, trial 2\n",
      "Accuracy: 0.887\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=-1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__max_features': 12}\n",
      "Average test accuracy for rf, 2, 0.8: 0.89425\n",
      "Average train accuracy for rf, 2, 0.8: 1.0\n",
      "Average val accuracy for rf, 2, 0.8: 0.8820019419719569\n",
      "Classifier 1, dataset 0, partition 0.2, trial 0\n",
      "Accuracy: 0.8505\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 0, partition 0.2, trial 1\n",
      "Accuracy: 0.85\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 0, partition 0.2, trial 2\n",
      "Accuracy: 0.8495\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Average test accuracy for lg, 0, 0.2: 0.85\n",
      "Average train accuracy for lg, 0, 0.2: 0.8554583730922106\n",
      "Average val accuracy for lg, 0, 0.2: 0.8494585540438083\n",
      "Classifier 1, dataset 0, partition 0.5, trial 0\n",
      "Accuracy: 0.8444\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 0, partition 0.5, trial 1\n",
      "Accuracy: 0.8408\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 0, partition 0.5, trial 2\n",
      "Accuracy: 0.8464\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 0, 0.5: 0.8438666666666667\n",
      "Average train accuracy for lg, 0, 0.5: 0.8606001888857923\n",
      "Average val accuracy for lg, 0, 0.5: 0.8533350990276206\n",
      "Classifier 1, dataset 0, partition 0.8, trial 0\n",
      "Accuracy: 0.84275\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 0, partition 0.8, trial 1\n",
      "Accuracy: 0.837\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 0, partition 0.8, trial 2\n",
      "Accuracy: 0.847375\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 0, 0.8: 0.842375\n",
      "Average train accuracy for lg, 0, 0.8: 0.8616655038322298\n",
      "Average val accuracy for lg, 0, 0.8: 0.8436650043346695\n",
      "Classifier 1, dataset 1, partition 0.2, trial 0\n",
      "Accuracy: 0.575\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1000, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 1, partition 0.2, trial 1\n",
      "Accuracy: 0.589\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 1, partition 0.2, trial 2\n",
      "Accuracy: 0.595\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "Average test accuracy for lg, 1, 0.2: 0.5863333333333333\n",
      "Average train accuracy for lg, 1, 0.2: 0.6102498315492508\n",
      "Average val accuracy for lg, 1, 0.2: 0.5853734798017345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 1, dataset 1, partition 0.5, trial 0\n",
      "Accuracy: 0.5926\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 1, partition 0.5, trial 1\n",
      "Accuracy: 0.5936\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 1, partition 0.5, trial 2\n",
      "Accuracy: 0.5816\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 0.1, 'clf__penalty': 'l2'}\n",
      "Average test accuracy for lg, 1, 0.5: 0.5892666666666667\n",
      "Average train accuracy for lg, 1, 0.5: 0.6207003523787691\n",
      "Average val accuracy for lg, 1, 0.5: 0.5698661388170545\n",
      "Classifier 1, dataset 1, partition 0.8, trial 0\n",
      "Accuracy: 0.56775\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1000, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 1, partition 0.8, trial 1\n",
      "Accuracy: 0.57125\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 1, partition 0.8, trial 2\n",
      "Accuracy: 0.57075\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 1, 0.8: 0.5699166666666666\n",
      "Average train accuracy for lg, 1, 0.8: 0.6544175359767563\n",
      "Average val accuracy for lg, 1, 0.8: 0.5708298118477759\n",
      "Classifier 1, dataset 2, partition 0.2, trial 0\n",
      "Accuracy: 0.851\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 1000, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 2, partition 0.2, trial 1\n",
      "Accuracy: 0.8395\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 2, partition 0.2, trial 2\n",
      "Accuracy: 0.8325\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 2, 0.2: 0.841\n",
      "Average train accuracy for lg, 2, 0.2: 0.844229125087722\n",
      "Average val accuracy for lg, 2, 0.2: 0.8410420471634594\n",
      "Classifier 1, dataset 2, partition 0.5, trial 0\n",
      "Accuracy: 0.8414\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 2, partition 0.5, trial 1\n",
      "Accuracy: 0.8434\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 2, partition 0.5, trial 2\n",
      "Accuracy: 0.8366\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 2, 0.5: 0.8404666666666667\n",
      "Average train accuracy for lg, 2, 0.5: 0.8471003478375954\n",
      "Average val accuracy for lg, 2, 0.5: 0.8415332559882466\n",
      "Classifier 1, dataset 2, partition 0.8, trial 0\n",
      "Accuracy: 0.840125\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__penalty': 'l1'}\n",
      "Classifier 1, dataset 2, partition 0.8, trial 1\n",
      "Accuracy: 0.840875\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l2', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l2'}\n",
      "Classifier 1, dataset 2, partition 0.8, trial 2\n",
      "Accuracy: 0.83475\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
      "          penalty='l1', random_state=0, solver='warn', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__penalty': 'l1'}\n",
      "Average test accuracy for lg, 2, 0.8: 0.8385833333333333\n",
      "Average train accuracy for lg, 2, 0.8: 0.8550832110826307\n",
      "Average val accuracy for lg, 2, 0.8: 0.8430004217110664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 2, dataset 0, partition 0.2, trial 0\n",
      "Accuracy: 0.854\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.2, trial 1\n",
      "Accuracy: 0.8585\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.2, trial 2\n",
      "Accuracy: 0.842\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Average test accuracy for svm, 0, 0.2: 0.8515\n",
      "Average train accuracy for svm, 0, 0.2: 0.8554373313988414\n",
      "Average val accuracy for svm, 0, 0.2: 0.846249793332891\n",
      "Classifier 2, dataset 0, partition 0.5, trial 0\n",
      "Accuracy: 0.8538\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.5, trial 1\n",
      "Accuracy: 0.8466\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.5, trial 2\n",
      "Accuracy: 0.8492\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Average test accuracy for svm, 0, 0.5: 0.8498666666666667\n",
      "Average train accuracy for svm, 0, 0.5: 0.8570660046104869\n",
      "Average val accuracy for svm, 0, 0.5: 0.8486643776032032\n",
      "Classifier 2, dataset 0, partition 0.8, trial 0\n",
      "Accuracy: 0.8365\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.8, trial 1\n",
      "Accuracy: 0.8415\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 0, partition 0.8, trial 2\n",
      "Accuracy: 0.84425\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Average test accuracy for svm, 0, 0.8: 0.84075\n",
      "Average train accuracy for svm, 0, 0.8: 0.8727502340352704\n",
      "Average val accuracy for svm, 0, 0.8: 0.851335593464529\n",
      "Classifier 2, dataset 1, partition 0.2, trial 0\n",
      "Accuracy: 0.572\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 0.1, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 1, partition 0.2, trial 1\n",
      "Accuracy: 0.6\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 1, partition 0.2, trial 2\n",
      "Accuracy: 0.59\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n",
      "Average test accuracy for svm, 1, 0.2: 0.5873333333333333\n",
      "Average train accuracy for svm, 1, 0.2: 0.6196041730092565\n",
      "Average val accuracy for svm, 1, 0.2: 0.5806664372239987\n",
      "Classifier 2, dataset 1, partition 0.5, trial 0\n",
      "Accuracy: 0.572\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 1, partition 0.5, trial 1\n",
      "Accuracy: 0.5832\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 1, partition 0.5, trial 2\n",
      "Accuracy: 0.5768\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 0.1, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Average test accuracy for svm, 1, 0.5: 0.5773333333333334\n",
      "Average train accuracy for svm, 1, 0.5: 0.619266785706765\n",
      "Average val accuracy for svm, 1, 0.5: 0.582201406857484\n",
      "Classifier 2, dataset 1, partition 0.8, trial 0\n",
      "Accuracy: 0.575125\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 2, dataset 1, partition 0.8, trial 1\n",
      "Accuracy: 0.573875\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 10, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Classifier 2, dataset 1, partition 0.8, trial 2\n",
      "Accuracy: 0.571\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 1, 'clf__degree': 2, 'clf__kernel': 'linear'}\n",
      "Average test accuracy for svm, 1, 0.8: 0.5733333333333334\n",
      "Average train accuracy for svm, 1, 0.8: 0.6554962008485247\n",
      "Average val accuracy for svm, 1, 0.8: 0.5554941168713624\n",
      "Classifier 2, dataset 2, partition 0.2, trial 0\n",
      "Accuracy: 0.8935\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.2, trial 1\n",
      "Accuracy: 0.8835\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.2, trial 2\n",
      "Accuracy: 0.8965\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n",
      "Average test accuracy for svm, 2, 0.2: 0.8911666666666667\n",
      "Average train accuracy for svm, 2, 0.2: 0.896208275234425\n",
      "Average val accuracy for svm, 2, 0.2: 0.8875833350288579\n",
      "Classifier 2, dataset 2, partition 0.5, trial 0\n",
      "Accuracy: 0.8858\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.5, trial 1\n",
      "Accuracy: 0.8816\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.5, trial 2\n",
      "Accuracy: 0.8898\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Average test accuracy for svm, 2, 0.5: 0.8857333333333334\n",
      "Average train accuracy for svm, 2, 0.5: 0.8952995915422757\n",
      "Average val accuracy for svm, 2, 0.5: 0.8801330284311966\n",
      "Classifier 2, dataset 2, partition 0.8, trial 0\n",
      "Accuracy: 0.87125\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 3, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.8, trial 1\n",
      "Accuracy: 0.86975\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Classifier 2, dataset 2, partition 0.8, trial 2\n",
      "Accuracy: 0.873625\n",
      "Best estimator: Pipeline(memory=None,\n",
      "     steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('clf', SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "Best params:  {'clf__C': 100, 'clf__degree': 2, 'clf__kernel': 'poly'}\n",
      "Average test accuracy for svm, 2, 0.8: 0.8715416666666667\n",
      "Average train accuracy for svm, 2, 0.8: 0.8868326526909088\n",
      "Average val accuracy for svm, 2, 0.8: 0.86482909696303\n"
     ]
    }
   ],
   "source": [
    "for classifier in range(3):\n",
    "    for dataset in range(3):        \n",
    "        for partition in partitions:\n",
    "            test_accs = []\n",
    "            train_accs = []\n",
    "            val_accs = []\n",
    "            for trial in range(3):\n",
    "                X = datasets[dataset]\n",
    "                y = labels[dataset]\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=partition, stratify=y)\n",
    "                \n",
    "                #Make pipeline\n",
    "                pipeline = Pipeline(\n",
    "                    [('scaler', MinMaxScaler()),\n",
    "                     ('clf', clfs[classifier]),                     \n",
    "                ])\n",
    "                clf = GridSearchCV(estimator=pipeline, param_grid=parameters[classifier], \n",
    "                                   n_jobs=-1, cv=3, return_train_score=True, iid=False)\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                print('Classifier {}, dataset {}, partition {}, trial {}'.format(classifier, dataset, partition, trial))\n",
    "                \n",
    "                train_accuracy = clf.cv_results_['mean_train_score'][clf.best_index_]\n",
    "                train_accs.append(train_accuracy)\n",
    "                \n",
    "                val_accuracy = clf.cv_results_['mean_test_score'][clf.best_index_]\n",
    "                val_accs.append(val_accuracy)\n",
    "                \n",
    "                test_accuracy = clf.score(X_test, y_test)\n",
    "                test_accs.append(test_accuracy)\n",
    "                \n",
    "                print('Accuracy: {}'.format(test_accuracy))\n",
    "\n",
    "                print('Best estimator:', clf.best_estimator_)\n",
    "            \n",
    "                print('Best params: ', clf.best_params_)\n",
    "            \n",
    "                clf_name = clf_names[classifier]\n",
    "                dirname = \"./classifier/{}/{}/{}/{}\".format(\n",
    "                    classifier, dataset, partition, trial\n",
    "                )\n",
    "               \n",
    "                if not os.path.exists(dirname):\n",
    "                    os.makedirs(dirname)\n",
    "                    \n",
    "                clf_dump = open(\"{}/{}.pkl\".format(\n",
    "                    dirname, clf_name\n",
    "                ),\"wb\")\n",
    "                pickle.dump(clf, clf_dump)\n",
    "                clf_dump.close()\n",
    "                \n",
    "                score_dump = open(\"{}/y_test.pkl\".format(\n",
    "                    dirname\n",
    "                ),\"wb\")\n",
    "                pickle.dump(y_test, score_dump)\n",
    "                score_dump.close()\n",
    "                \n",
    "            avg_test = mean(test_accs)\n",
    "            avg_train = mean(train_accs)\n",
    "            avg_val = mean(val_accs)\n",
    "            \n",
    "            test_accs.clear()\n",
    "            train_accs.clear()\n",
    "            val_accs.clear()\n",
    "            \n",
    "            print('Average test accuracy for {}, {}, {}: {}'.format(\n",
    "                clf_names[classifier], \n",
    "                dataset,\n",
    "                partition,\n",
    "                avg_test\n",
    "            ))\n",
    "            \n",
    "            print('Average train accuracy for {}, {}, {}: {}'.format(\n",
    "                clf_names[classifier], \n",
    "                dataset,\n",
    "                partition,\n",
    "                avg_train\n",
    "            ))\n",
    "            \n",
    "            print('Average val accuracy for {}, {}, {}: {}'.format(\n",
    "                clf_names[classifier], \n",
    "                dataset,\n",
    "                partition,\n",
    "                avg_val\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
